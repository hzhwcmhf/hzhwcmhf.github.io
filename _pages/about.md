---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Ph.D. candidate in [CoAI Group](http://coai.cs.tsinghua.edu.cn/), Department of Computer Science and Technology, Tsinghua University. My adviser is [Prof.Minlie Huang](http://coai.cs.tsinghua.edu.cn/hml).

I am particularly interested in

* Natural Language Generation
* Non-Autoregressive Text Generation

Education 
======

- **2018.8 - 2023.7 (Expected)**: Ph.D., Department of Computer Science and Technology, Tsinghua University (Scholarship for Future Scholars, Top 3% of Ph.D. Students at Tsinghua Univ.)
- **2014.9 - 2018.7**: B.Eng., Department of Computer Science and Technology, Tsinghua University. (GPA: 93/100, Rank: 3/151.)
- **2016.4-2016.8**: Exchange Student at Tokyo University, Japan. (Fully sponsored by China Scholarship Council.)

Publications
======

**Conference Papers**

* **Fei Huang**, Hao Zhou, Yang Liu, Hang Li, Minlie Huang. *Directed Acyclic Transformer for Non-Autoregressive Machine Translation.* **ICML 2022 (CCF-A, Long Paper, Patent Pending).** [[Paper]](https://arxiv.org/abs/2205.07459) [[Code]](https://github.com/thu-coai/DA-Transformer)
* **Fei Huang**, Tianhua Tao, Hao Zhou, Lei Li, Minlie Huang. *On the Learning of Non-Autoregressive Transformers.* **ICML 2022 (CCF-A, Long Paper).** [[Paper]](https://arxiv.org/abs/2206.05975)
* **Fei Huang**, Zikai Chen, Chen Henry Wu, Qihan Guo, Xiaoyan Zhu, Minlie Huang. *NAST: A Non-Autoregressive Generator with Word Alignment for Unsupervised Text Style Transfer.* **Findings of ACL 2021 (Long Paper, Patent Pending).** [[Paper]](https://aclanthology.org/2021.findings-acl.138/) [[Code]](https://github.com/thu-coai/NAST)
* Yilin Niu#, **Fei Huang#**, Jiaming Liang, Wenkai Chen, Xiaoyan Zhu, Minlie Huang. *A Semantic-based Method for Unsupervised Commonsense Question Answering.* **ACL 2021 (Co-first Author, CCF-A, Long Paper).** [[Paper]](https://aclanthology.org/2021.acl-long.237/) [[Code]](https://github.com/heyLinsir/Semantic-based-QA)
* Pei Ke#, **Fei Huang#**, Minlie Huang, Xiaoyan Zhu. *ARAML: A Stable Adversarial Training Framework for Text Generation.* **EMNLP 2019 (Co-first Author, CCF-B, Long Paper, Patent Pending).** [[Paper]](https://aclanthology.org/D19-1436/) [[Code]](https://github.com/kepei1106/ARAML)

**Journal Paper**

* Jian Guan, **Fei Huang**, Zhihao Zhao, Xiaoyan Zhu, Minlie Huang. *A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation.* **TACL, 2020 (IF=9.2, 104 Citations).**  [[Paper]](https://aclanthology.org/2020.tacl-1.7/) [[Code]](https://github.com/JianGuanTHU/CommonsenseStoryGen)

**Book**

* 黄民烈, **黄斐**, 朱小燕. *现代自然语言生成 (Modern Natural Language Generation).* 北京:电子工业出版社,2021. [[Preview]](https://github.com/thu-coai/NLG_book)

**Preprints**

* **Fei Huang**, Dazhen Wan, Zhihong Shao, Pei Ke, Jian Guan, Yilin Niu, Xiaoyan Zhu, Minlie Huang. *Cotk: An open-source toolkit for fast development and fair evaluation of text generation.* 2020. **(Toolkit Paper. 121 Stars on Github.)** [[Paper]](https://arxiv.org/pdf/2002.00583.pdf) [[Code]](https://github.com/thu-coai/cotk)
* **Fei Huang**, Jian Guan, Pei Ke, Qihan Guo, Xiaoyan Zhu, Minlie Huang. *A text GAN for language generation with non-autoregressive generator.* 2020. [[Paper]](https://openreview.net/pdf?id=wOI9hqkvu_)

Experience
======

- **2021.3 - 2022.5: NLP Research Intern at ByteDance AI Lab**
  - **Aims**: Developing new paradigms for language generation, mainly focusing on **non-autoregressive text generation**.
  - **Theory Contribution**: I revealed the theoretical challenges in the learning of non-autoregressive generators and proposed a unified perspective to understand existing training objectives. ([Paper Link](https://arxiv.org/abs/2206.05975))
  - **Empirical Contribution**: I proposed a new model that remarkably improves the generation quality of non-autoregressive generators. (*+3 BLEU, outperform the vanilla Transformer and achieve 7~14 times decoding speedup.*)  ([Paper Link](https://arxiv.org/abs/2205.07459))
  - **Open-source Framework**: I developed a framework with highly efficient training and inference based on [Lightseq](https://github.com/bytedance/lightseq), including operations implemented in *Cuda and multi-threaded C++*. ([Code Link](https://github.com/thu-coai/DA-Transformer))
  - **Two papers are published and one patent is pending**.
- **2018.11 - 2020.8: Leader of Open-Source Toolkit Development for Text Generation**
  - CoTK: An open-source python library for fast development and fair evaluation of text generation. ([Github Link](https://github.com/thu-coai/cotk), 121 stars.)
  - It provides unified APIs for different datasets, a signature mechanism to avoid unfair comparisons in evaluation, and implementations for many text generation models.
  - I led this project and worked with 5 other students of the CoAI group. I designed the API, maintained the developing process, and implemented parts of the toolkit including dataset I/O, models, and evaluation. 
- **2019.9 - 2020.9:  Student Author for the Book -- Modern Natural Language Generation**
  - This book is the first Chinese book that introduces various deep learning methods in natural language generation.
  - I mainly wrote Chapter 6 (Generative Adversarial Networks for Language Generation), Chapter 7 (Non-Autoregressive Text Generation), and part of Chapter 10 (Tasks and Resources for Language Generation) and Chapter 11 (Evaluation for Language Generation).
- **2019.9 - Present: Sub-group Leader for Natural Language Generation (NLG) in the CoAI group.**
  - Our sub-group consists of five Ph.D. students and several undergraduates. We aim at resolving critical problems in NLG. Our research topics include non-autoregressive generation, bias in language models, long text generation, pretrained language models, and the evaluation of NLG. Our members publish 17 papers as the first author in these three years, including 7 in CCF-A and 3 in CCF-B.
  - I coordinate weekly discussions and academic presentations in the sub-group. I also help the management of research plans and actively provide suggestions for the projects. I also lead many projects working with undergraduates.

Awards
=====

* **2018-Present**: Scholarship for Future Scholars (Top 3% of Ph.D. Student at Tsinghua University, 30,000 RMB / year)
* **2015-2017**: Academic Excellence Scholarship (3,000 ~ 6,000 RMB / year)
* **2014**: Second Class Scholarship for Undergraduate Freshmen (20,000 RMB)
* **2013**: Gold Medal in National Olympiad in Informatics (NOI) (Rank 5)

Skills
=====

* **Programming Language**: Python, C++
* **Skills of Deep Learning**: 
  * I am familiar with various deep learning frameworks and toolkits, e.g., PyTorch, Tensorflow, Fairseq, LightSeq.
  * I can implement operations with Cuda to accelerate training and inference.
* **Algorithm**: I am good at algorithms, e.g., Dynamic Programming, Data Structures, Graph Theory.
* **Language**: Chinese (Native Speaker), English (CET-6 518), Japanese (JLPT-N1)

Teaching
=====

* **Artificial Neural Network** (Undergraduate Course at Tsinghua University):
	* 2018,2021: Teaching Assistant; 2019,2020: Head TA
	* Give lectures about generative adversarial networks and text generation.
	* Help the professor in preparing slides and homework. 
	
* **Object-Oriented Programming** (Undergraduate Course at Tsinghua University):
	* 2018: Teaching Assistant; 2019-2021: Head TA; 2022: Honorary TA
	* Give lectures about the fundamental of programming and operating system.
	* Help the professor in preparing slides, homework, and examinations.
	* Develop and maintain a website for online programming exercises.


Services
=====

* **Conference Reviewer**: ACL/ARR(2021-2022), EMNLP(2021-2022), NLPCC(2022)
* **Journal Reviewer**: TNNLS, TASLP


